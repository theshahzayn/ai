{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f4fk07Mx6IsQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#22k5093\n"
      ],
      "metadata": {
        "id": "gBL3BqI36Sry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LAB FINAL AI\n"
      ],
      "metadata": {
        "id": "LrGO_ro_6P69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QUESTION 1"
      ],
      "metadata": {
        "id": "f4fk07Mx6IsQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOJdrZtw58_l"
      },
      "outputs": [],
      "source": [
        "#KMEAN\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "X = data.values  #\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "inertia = []\n",
        "for n_clusters in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), inertia, marker='o')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.xticks(range(1, 11))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "k = 3\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "kmeans.fit(X_scaled)\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "data['Cluster'] = cluster_labels\n",
        "print(\"Cluster Counts:\")\n",
        "print(data['Cluster'].value_counts())\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=cluster_labels, cmap='viridis')\n",
        "plt.title('K-means Clustering')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QUESTION 2"
      ],
      "metadata": {
        "id": "pTPjmuvX6p1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "p_A = 0.3\n",
        "p_B_given_A = 0.8\n",
        "p_B_given_not_A = 0.2\n",
        "p_A_and_B = p_A * p_B_given_A\n",
        "p_not_A_and_B = (1 - p_A) * p_B_given_not_A\n",
        "p_B = p_A_and_B + p_not_A_and_B\n",
        "p_A_given_B = p_A_and_B / p_B\n",
        "print(\"P(A and B):\", p_A_and_B)\n",
        "print(\"P(~A and B):\", p_not_A_and_B)\n",
        "print(\"P(B):\", p_B)\n",
        "print(\"P(A | B):\", p_A_given_B)\n"
      ],
      "metadata": {
        "id": "F7y3O76k9c_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "model = BayesianModel([('A', 'B')])\n",
        "\n",
        "cpd_A = TabularCPD(variable='A', variable_card=2, values=[[0.7], [0.3]])\n",
        "cpd_B = TabularCPD(variable='B', variable_card=2, values=[[0.8, 0.2], [0.2, 0.8]], evidence=['A'], evidence_card=[2])\n",
        "\n",
        "model.add_cpds(cpd_A, cpd_B)\n",
        "inference = VariableElimination(model)\n",
        "result = inference.query(variables=['A'], evidence={'B': 1})\n",
        "print(\"P(A = 0 | B = 1):\", result.values[0])\n",
        "result = inference.query(variables=['B'], evidence={'A': 0})\n",
        "print(\"P(B = 1 | A = 0):\", result.values[1])\n"
      ],
      "metadata": {
        "id": "y6bg84zl9opc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LWx55tPk6O0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hmmlearn import hmm\n",
        "import numpy as np\n",
        "\n",
        "n_components = 2\n",
        "n_features = 3\n",
        "model = hmm.MultinomialHMM(n_components=n_components, n_iter=100)\n",
        "model.startprob_ = np.array([0.6, 0.4])\n",
        "model.transmat_ = np.array([[0.7, 0.3],\n",
        "                             [0.4, 0.6]])\n",
        "model.emissionprob_ = np.array([[0.1, 0.4, 0.5],\n",
        "                                 [0.6, 0.3, 0.1]])\n",
        "\n",
        "# Example: Observations [0, 1, 2, 0, 1, 2]\n",
        "X = np.array([[0, 1, 2, 0, 1, 2]]).T\n",
        "\n",
        "model.fit(X)\n",
        "\n",
        "hidden_states = model.predict(X)\n",
        "print(\"Most likely sequence of hidden states:\", hidden_states)\n"
      ],
      "metadata": {
        "id": "yaRxBzFn-HKj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}